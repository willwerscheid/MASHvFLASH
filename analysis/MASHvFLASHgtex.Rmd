---
title: "MASH v FLASH analysis of GTEx data (strong tests)"
output: 
  workflowr::wflow_html:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Here I compare MASH and FLASH fits to some GTEx data. The dataset is comprised of $z$-scores across 44 tissues for approximately 16000 tests, which correspond to the "top" eQTL for each gene (that is, the eQTL with the largest (absolute) raw $z$-score). 

To evaluate the fits, I randomly delete entries from the dataset, then I fit MASH and FLASH objects and use the fitted objects to impute the missing data. I run four experiments in which I delete 1%, 5%, 10%, and 25% of entries, and I compute the mean-squared error for the imputed values and the percentage of 95% confidence intervals that contain the "true" values. 

Of course, the deleted entries are observed values rather than true values, so results here should be taken with a grain of salt!
 
For the code used in this analysis, see [below](#code).

## Fitting methods

In addition to a MASH fit, I used the "OHF" and "Zero" methods described in my [simulation study](MASHvFLASHsims.html) to fit FLASH objects. (Since the "Zero" and "OHL" methods give very similar results, I did not use the latter here.) For each of the FLASH methods, I produce one fit using point-normal priors (`ebnm_fn = "ebnm_pn"`) and another fit using a more flexible class of `ash` priors (`ebnm_fn = "ebnm_ash"`). In sum, I generated a total of five fits for each experiment, which I denote as `mash`, `pn.OHF`, `ash.OHF`, `pn.zero`, and `ash.zero`.

Each of these methods assumes that noise is independent among conditions. It is not, but it is still useful to see how the methods compare when applied to a real dataset. 

## Results

Since the experiments take a long time to run, I pre-run them and load the results from file.

```{r load_fits}
fl_diag <- readRDS("./output/MASHvFLASHgtex/fldiag.rds")
fl_t <- readRDS("./output/MASHvFLASHgtex/flt.rds")
m_diag <- readRDS("./output/MASHvFLASHgtex/mdiag.rds")
m_t <- readRDS("./output/MASHvFLASHgtex/mt.rds")
```

Comparisons of mean-squared error and confidence interval coverage are as follows. FLASH consistently outperforms MASH, with the "OHF" method outperforming the "Zero" method. Using `ash` priors gives slightly better results than using point-normal priors.

```{r res1}
fl_fit_names <- c("pn.zero", "pn.OHF", "ash.zero", "ash.OHF")
method.names <- c(fl_fit_names, "mash")

all_t <- rbind(sapply(fl_t, unlist), unlist(m_t))
rownames(all_t) <- method.names

fl_mse <- sapply(fl_diag, function(x) {sapply(x, function(y) {y$mse})})
all_mse <- rbind(fl_mse, sapply(m_diag, function(x) {x$mse}))
rownames(all_mse) <- method.names

fl_ci <- sapply(fl_diag, function(x) {sapply(x, function(y) {y$ci})})
all_ci <- rbind(fl_ci, sapply(m_diag, function(x) {x$ci}))
rownames(all_ci) <- method.names

plot.order <- c(2, 4, 1, 3, 5)

boxplot(t(all_mse[plot.order, ]), ylim=c(0, 1), ylab = "MSE",
        main = "Mean-squared error")

boxplot(t(all_ci[plot.order, ]), ylim=c(0, 1), ylab = "coverage",
        main = "Proportion of 95% CIs containing true value")
```

The total time required by each method (including both the time needed to produce a fit and the time needed to compute posterior summaries) is as follows. While `ash` priors give slightly better results than point-normal priors, they take approximately twice as long to fit. 

```{r res2}
boxplot(t(all_t[plot.order, ]), ylim=c(0, 60), ylab="minutes",
        main="Time needed for fit and MSE and CI calculations")
```


## Conclusions

Of all methods, only the "OHF" methods give satisfactory results for confidence interval coverage. They also do very well in terms of mean-squared error. Indeed, I am surprised that their MSE is so much smaller than 1. The observational error is supposed to be equal to 1, so I would expect it to be very difficult for any method to achieve an MSE smaller than 1. Indeed, if the errors were uncorrelated, then this would be true, but as I mentioned above, observational errors are almost certainly correlated across tissues. Thus, much of the reason for FLASH's success here could be due to its ability to account for such correlations. Still, the results are very encouraging.


## Code

for fitting MASH and FLASH objects...
```{r fits, code=readLines("../code/fits.R")}
```

...for evaluating performance...
```{r utils, code=readLines("../code/utils.R")}
```

...for evaluating peformance on data imputation tasks...
```{r mashvflash, code=readLines("../code/gtexutils.R")}
```

...and the main function calls.
```{r main, code=readLines("../code/MASHvFLASHgtex.R"), eval=FALSE}
```
